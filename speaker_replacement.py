import pandas as pd
import numpy as np
import re
import os
from collections import defaultdict

class BatchSpeakerAnalyzer:
    def __init__(self):
        self.stats = {
            "valid_utterances": 0,
            "invalid_utterances": 0,
            "simultaneous_speech_segments": 0
        }
        self.global_stats = {
            "total_videos": 0,
            "processed_videos": 0,
            "failed_videos": 0,
            "total_utterances": 0,
            "total_correct": 0
        }
    
    def ensure_path_exists(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶è·¯å¾„çš„ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
        try:
            directory = os.path.dirname(file_path)
            if directory and not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)
                print(f"âœ… åˆ›å»ºç›®å½•: {directory}")
            return True
        except Exception as e:
            print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥: {e}")
            return False
    
    def get_unique_videos(self, csv_path):
        """ä»CSVæ–‡ä»¶ä¸­è·å–æ‰€æœ‰å”¯ä¸€çš„è§†é¢‘åç§°"""
        try:
            df = pd.read_csv(csv_path)
            if 'video_id' not in df.columns:
                print(f"âŒ CSVæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°'video_id'åˆ—")
                return []
            
            unique_videos = df['video_id'].unique().tolist()
            print(f"ğŸ“¹ æ‰¾åˆ° {len(unique_videos)} ä¸ªå”¯ä¸€è§†é¢‘")
            return unique_videos
            
        except Exception as e:
            print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def find_transcript_file(self, video_name, transcript_base_dir):
        """æ ¹æ®è§†é¢‘åç§°æŸ¥æ‰¾å¯¹åº”çš„transcriptæ–‡ä»¶"""
        # å°†.mp4æ”¹ä¸º.txt
        if video_name.endswith('.mp4'):
            transcript_name = video_name.replace('.mp4', '.txt')
        else:
            transcript_name = video_name + '.txt'
        
        transcript_path = os.path.join(transcript_base_dir, transcript_name)
        
        if os.path.exists(transcript_path):
            return transcript_path
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°transcriptæ–‡ä»¶: {transcript_path}")
            return None
    
    def time_to_seconds(self, time_str):
        """Convert time string (mm:ss) to seconds"""
        parts = time_str.split(':')
        minutes = int(parts[0])
        seconds = int(parts[1])
        return minutes * 60 + seconds
    
    def parse_entity_id(self, entity_id):
        """è§£æentity_idè·å–start_time, end_time, player_id"""
        parts = entity_id.split('_')
        
        if len(parts) < 3:
            raise ValueError(f"Invalid entity_id format: {entity_id}")
        
        try:
            player_id = int(parts[-1])
            end_time_str = parts[-2]
            start_time_str = parts[-3]
            
            if '.' in start_time_str:
                start_time = int(float(start_time_str))
            else:
                start_time = int(start_time_str)
                
            if '.' in end_time_str:
                end_time = int(float(end_time_str))
            else:
                end_time = int(end_time_str)
            
            return start_time, end_time, player_id
            
        except (ValueError, IndexError) as e:
            raise ValueError(f"Invalid entity_id format: {entity_id}") from e
    
    def parse_transcript(self, transcript_path):
        """è§£ætranscriptæ–‡ä»¶"""
        with open(transcript_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        utterances = []
        timestamp_to_players = {}
        
        for i, line in enumerate(lines):
            player_match = re.match(r'\[Player(\d+)\]\s*\((\d+):(\d+)\):', line)
            if player_match:
                player_id = int(player_match.group(1))
                minutes = int(player_match.group(2))
                seconds = int(player_match.group(3))
                start_time = minutes * 60 + seconds
                start_time_str = f"{minutes:02d}:{seconds:02d}"
                
                if start_time not in timestamp_to_players:
                    timestamp_to_players[start_time] = []
                timestamp_to_players[start_time].append({
                    "player_id": player_id,
                    "line_idx": i,
                    "start_time_str": start_time_str
                })
        
        sorted_timestamps = sorted(timestamp_to_players.keys())
        
        for i, timestamp in enumerate(sorted_timestamps):
            players = timestamp_to_players[timestamp]
            
            end_time = None
            if i < len(sorted_timestamps) - 1:
                next_timestamp = sorted_timestamps[i+1]
                if next_timestamp > timestamp:
                    end_time = next_timestamp
            
            if end_time is None:
                if i == len(sorted_timestamps) - 1:
                    end_time = timestamp + 10
                else:
                    end_time = timestamp + 5
            
            if end_time is None or timestamp >= end_time:
                self.stats["invalid_utterances"] += len(players)
                continue
            
            if len(players) > 1:
                self.stats["simultaneous_speech_segments"] += 1
            
            for player_info in players:
                utterances.append({
                    "player_id": player_info["player_id"],
                    "start_time": timestamp,
                    "end_time": end_time,
                    "start_time_str": player_info["start_time_str"],
                    "is_simultaneous": len(players) > 1
                })
                self.stats["valid_utterances"] += 1
        
        return utterances
    
    def predict_speakers(self, stats_df, score_method='max', top_k=3):
        """ä¸ºæ¯ä¸ªæ—¶é—´æ®µé¢„æµ‹è¯´è¯è€…"""
        predictions = []
        sort_column = 'max_score' if score_method == 'max' else 'avg_score'
        
        for time_segment, group in stats_df.groupby('time_segment'):
            group_sorted = group.sort_values(sort_column, ascending=False)
            top_players = group_sorted.head(top_k)
            
            prediction = {
                'start_time': int(group_sorted.iloc[0]['start_time']),
                'end_time': int(group_sorted.iloc[0]['end_time']),
                'predicted_players': [],
                'predicted_player_ids': [],
                'score_method': score_method,
                'all_players': {}
            }
            
            for _, row in top_players.iterrows():
                primary_score = float(row[sort_column])
                
                player_info = {
                    'player_id': int(row['player_id']),
                    'max_score': float(row['max_score']),
                    'avg_score': float(row['avg_score']),
                    'primary_score': primary_score
                }
                prediction['predicted_players'].append(player_info)
                prediction['predicted_player_ids'].append(int(row['player_id']))
            
            for _, row in group_sorted.iterrows():
                prediction['all_players'][int(row['player_id'])] = {
                    'max_score': float(row['max_score']),
                    'avg_score': float(row['avg_score']),
                    'frame_count': int(row['frame_count'])
                }
            
            predictions.append(prediction)
        
        predictions.sort(key=lambda x: x['start_time'])
        return predictions
    
    def calculate_player_statistics(self, df_video):
        """è®¡ç®—å•ä¸ªè§†é¢‘çš„playerç»Ÿè®¡ä¿¡æ¯"""
        df_video = df_video.copy()
        
        df_video[['start_time', 'end_time', 'player_id']] = df_video['entity_id'].apply(
            lambda x: pd.Series(self.parse_entity_id(x))
        )
        
        df_video['time_segment'] = df_video['start_time'].astype(str) + '_' + df_video['end_time'].astype(str)
        
        stats = df_video.groupby(['time_segment', 'start_time', 'end_time', 'player_id'])['score'].agg([
            'max', 'mean', 'count'
        ]).reset_index()
        
        stats.columns = ['time_segment', 'start_time', 'end_time', 'player_id', 'max_score', 'avg_score', 'frame_count']
        
        return stats
    
    def calculate_utterance_level_accuracy(self, predictions, original_txt_path):
        """è®¡ç®—utteranceçº§åˆ«çš„å‡†ç¡®ç‡"""
        with open(original_txt_path, 'r', encoding='utf-8') as f:
            original_lines = f.readlines()
        
        original_utterances = []
        for line in original_lines:
            player_match = re.match(r'\[Player(\d+)\]\s*\((\d+):(\d+)\):(.*)', line)
            if player_match:
                original_player = int(player_match.group(1))
                minutes = int(player_match.group(2))
                seconds = int(player_match.group(3))
                timestamp = minutes * 60 + seconds
                content = player_match.group(4)
                
                original_utterances.append({
                    'timestamp': timestamp,
                    'original_player': original_player,
                    'minutes': minutes,
                    'seconds': seconds,
                    'content': content.strip(),
                    'time_str': f"{minutes:02d}:{seconds:02d}"
                })
        
        utterance_results = []
        correct_count = 0
        total_count = len(original_utterances)
        
        for utterance in original_utterances:
            predicted_player = None
            prediction_score = 0.0
            
            for pred in predictions:
                if pred['start_time'] <= utterance['timestamp'] < pred['end_time']:
                    if pred['predicted_player_ids']:
                        predicted_player = pred['predicted_player_ids'][0]
                        prediction_score = pred['predicted_players'][0]['primary_score']
                    break
            
            if predicted_player is None:
                predicted_player = utterance['original_player']
                prediction_score = 0.0
            
            is_correct = predicted_player == utterance['original_player']
            if is_correct:
                correct_count += 1
            
            utterance_results.append({
                'timestamp': utterance['timestamp'],
                'time_str': utterance['time_str'],
                'original_player': utterance['original_player'],
                'predicted_player': predicted_player,
                'prediction_score': prediction_score,
                'is_correct': is_correct,
                'content_preview': utterance['content'][:30] + '...' if len(utterance['content']) > 30 else utterance['content']
            })
        
        overall_accuracy = correct_count / total_count if total_count > 0 else 0
        
        return {
            'utterance_results': utterance_results,
            'overall_accuracy': overall_accuracy,
            'correct_count': correct_count,
            'total_count': total_count
        }
    
    def generate_utterance_replacement_txt(self, accuracy_data, original_txt_path, output_path):
        """ç”Ÿæˆæ›¿æ¢çš„txtæ–‡ä»¶"""
        results = accuracy_data['utterance_results']
        
        with open(original_txt_path, 'r', encoding='utf-8') as f:
            original_lines = f.readlines()
        
        modified_lines = []
        utterance_index = 0
        
        for line in original_lines:
            player_match = re.match(r'\[Player(\d+)\]\s*\((\d+):(\d+)\):(.*)', line)
            
            if player_match and utterance_index < len(results):
                result = results[utterance_index]
                minutes = int(player_match.group(2))
                seconds = int(player_match.group(3))
                content = player_match.group(4)
                
                time_str = f"{minutes:02d}:{seconds:02d}"
                new_line = f"[Player{result['predicted_player']}] ({time_str}):{content}"
                
                if not new_line.endswith('\n'):
                    new_line += '\n'
                
                modified_lines.append(new_line)
                utterance_index += 1
            else:
                modified_lines.append(line)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.ensure_path_exists(output_path)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for line in modified_lines:
                f.write(line)
        
        return accuracy_data['overall_accuracy']
    
    def process_single_video(self, video_name, csv_data, transcript_base_dir, output_base_dir, score_method='max'):
        """å¤„ç†å•ä¸ªè§†é¢‘"""
        print(f"\nğŸ¬ å¤„ç†è§†é¢‘: {video_name}")
        
        try:
            # 1. æŸ¥æ‰¾transcriptæ–‡ä»¶
            transcript_path = self.find_transcript_file(video_name, transcript_base_dir)
            if not transcript_path:
                print(f"âŒ è·³è¿‡è§†é¢‘ {video_name}: æ‰¾ä¸åˆ°transcriptæ–‡ä»¶")
                return None
            
            # 2. è¿‡æ»¤è¯¥è§†é¢‘çš„æ•°æ®
            video_data = csv_data[csv_data['video_id'] == video_name].copy()
            if len(video_data) == 0:
                print(f"âŒ è·³è¿‡è§†é¢‘ {video_name}: CSVä¸­æ²¡æœ‰æ•°æ®")
                return None
            
            print(f"   ğŸ“Š æ•°æ®è¡Œæ•°: {len(video_data)}")
            
            # 3. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            stats_df = self.calculate_player_statistics(video_data)
            print(f"   ğŸ“ˆ ç»Ÿè®¡å®Œæˆ: {len(stats_df)} ä¸ªplayer-æ—¶é—´æ®µç»„åˆ")
            
            # 4. ç”Ÿæˆé¢„æµ‹
            predictions = self.predict_speakers(stats_df, score_method=score_method)
            print(f"   ğŸ”® é¢„æµ‹å®Œæˆ: {len(predictions)} ä¸ªæ—¶é—´æ®µ")
            
            # 5. è®¡ç®—utteranceçº§åˆ«å‡†ç¡®ç‡
            accuracy_data = self.calculate_utterance_level_accuracy(predictions, transcript_path)
            print(f"   ğŸ“Š Utteranceå‡†ç¡®ç‡: {accuracy_data['overall_accuracy']:.2%}")
            
            # 6. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
            if video_name.endswith('.mp4'):
                output_filename = video_name.replace('.mp4', '.txt')
            else:
                output_filename = video_name + '.txt'
            
            output_path = os.path.join(output_base_dir, output_filename)
            final_accuracy = self.generate_utterance_replacement_txt(accuracy_data, transcript_path, output_path)
            
            print(f"   ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
            print(f"   âœ… å¤„ç†å®Œæˆ: {accuracy_data['correct_count']}/{accuracy_data['total_count']} utterancesæ­£ç¡®")
            
            return {
                'video_name': video_name,
                'accuracy': final_accuracy,
                'correct_count': accuracy_data['correct_count'],
                'total_count': accuracy_data['total_count'],
                'output_path': output_path
            }
            
        except Exception as e:
            print(f"âŒ å¤„ç†è§†é¢‘ {video_name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def process_all_videos(self, csv_path, transcript_base_dir, output_base_dir, score_method='max'):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘"""
        print("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†è§†é¢‘...")
        print(f"   ğŸ“ CSVæ–‡ä»¶: {csv_path}")
        print(f"   ğŸ“ Transcriptç›®å½•: {transcript_base_dir}")
        print(f"   ğŸ“ è¾“å‡ºç›®å½•: {output_base_dir}")
        print(f"   ğŸ¯ è¯„åˆ†æ–¹æ³•: {score_method}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.ensure_path_exists(os.path.join(output_base_dir, "dummy.txt"))
        
        # è¯»å–CSVæ•°æ®
        try:
            csv_data = pd.read_csv(csv_path)
            print(f"   ğŸ“Š CSVæ•°æ®åŠ è½½å®Œæˆ: {len(csv_data)} è¡Œ")
        except Exception as e:
            print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            return
        
        # è·å–æ‰€æœ‰è§†é¢‘
        unique_videos = self.get_unique_videos(csv_path)
        if not unique_videos:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è§†é¢‘")
            return
        
        self.global_stats["total_videos"] = len(unique_videos)
        
        # å¤„ç†æ¯ä¸ªè§†é¢‘
        results = []
        for i, video_name in enumerate(unique_videos, 1):
            print(f"\n{'='*60}")
            print(f"è¿›åº¦: {i}/{len(unique_videos)} - {video_name}")
            print(f"{'='*60}")
            
            result = self.process_single_video(
                video_name, csv_data, transcript_base_dir, output_base_dir, score_method
            )
            
            if result:
                results.append(result)
                self.global_stats["processed_videos"] += 1
                self.global_stats["total_utterances"] += result['total_count']
                self.global_stats["total_correct"] += result['correct_count']
            else:
                self.global_stats["failed_videos"] += 1
        
        # æ‰“å°æ€»ç»“
        self.print_batch_summary(results, score_method)
        
        # ä¿å­˜ç»“æœåˆ°CSV
        self.save_batch_results(results, output_base_dir, score_method)
    
    def print_batch_summary(self, results, score_method):
        """æ‰“å°æ‰¹é‡å¤„ç†æ€»ç»“"""
        print(f"\n" + "="*80)
        print(f"æ‰¹é‡å¤„ç†å®Œæˆæ€»ç»“ ({score_method}æ–¹æ³•)")
        print("="*80)
        
        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   æ€»è§†é¢‘æ•°: {self.global_stats['total_videos']}")
        print(f"   æˆåŠŸå¤„ç†: {self.global_stats['processed_videos']}")
        print(f"   å¤„ç†å¤±è´¥: {self.global_stats['failed_videos']}")
        print(f"   æˆåŠŸç‡: {self.global_stats['processed_videos']/self.global_stats['total_videos']:.1%}")
        
        if results:
            # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
            total_utterances = self.global_stats['total_utterances']
            total_correct = self.global_stats['total_correct']
            overall_accuracy = total_correct / total_utterances if total_utterances > 0 else 0
            
            print(f"\nğŸ“ˆ å‡†ç¡®ç‡ç»Ÿè®¡:")
            print(f"   æ€»utterances: {total_utterances}")
            print(f"   æ€»æ­£ç¡®æ•°: {total_correct}")
            print(f"   **æ€»ä½“utteranceå‡†ç¡®ç‡: {overall_accuracy:.2%}**")
            
            # å„è§†é¢‘å‡†ç¡®ç‡åˆ†å¸ƒ
            accuracies = [r['accuracy'] for r in results]
            print(f"\nğŸ“Š å„è§†é¢‘å‡†ç¡®ç‡åˆ†å¸ƒ:")
            print(f"   æœ€é«˜å‡†ç¡®ç‡: {max(accuracies):.2%}")
            print(f"   æœ€ä½å‡†ç¡®ç‡: {min(accuracies):.2%}")
            print(f"   å¹³å‡å‡†ç¡®ç‡: {np.mean(accuracies):.2%}")
            print(f"   å‡†ç¡®ç‡æ ‡å‡†å·®: {np.std(accuracies):.2%}")
            
            # æ˜¾ç¤ºå‰5å’Œå5çš„è§†é¢‘
            results_sorted = sorted(results, key=lambda x: x['accuracy'], reverse=True)
            
            print(f"\nğŸ† å‡†ç¡®ç‡æœ€é«˜çš„5ä¸ªè§†é¢‘:")
            for i, result in enumerate(results_sorted[:5], 1):
                print(f"   {i}. {result['video_name']}: {result['accuracy']:.2%} "
                      f"({result['correct_count']}/{result['total_count']})")
            
            print(f"\nğŸ“‰ å‡†ç¡®ç‡æœ€ä½çš„5ä¸ªè§†é¢‘:")
            for i, result in enumerate(results_sorted[-5:], 1):
                print(f"   {i}. {result['video_name']}: {result['accuracy']:.2%} "
                      f"({result['correct_count']}/{result['total_count']})")
    
    def save_batch_results(self, results, output_base_dir, score_method):
        """ä¿å­˜æ‰¹é‡å¤„ç†ç»“æœåˆ°CSV"""
        if not results:
            return
        
        results_df = pd.DataFrame(results)
        results_csv_path = os.path.join(output_base_dir, f"batch_results_{score_method}.csv")
        results_df.to_csv(results_csv_path, index=False)
        print(f"\nğŸ’¾ æ‰¹é‡ç»“æœå·²ä¿å­˜åˆ°: {results_csv_path}")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    csv_path = "/mnt/data2/datasets/xpeng/mmsi/ego4d_asd_test/csv/val_res.csv"
    transcript_base_dir = "/mnt/data2/datasets/xpeng/mmsi/ego4d/transcripts/anonymized/"
    output_base_dir = "/mnt/data2/datasets/xpeng/mmsi/ego4d_asd_test/transcripts_r"
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = BatchSpeakerAnalyzer()
    
    # é€‰æ‹©è¯„åˆ†æ–¹æ³• ('max' æˆ– 'avg')
    score_method = 'avg'  # å¯ä»¥æ”¹ä¸º 'max' æ¥æµ‹è¯•ä¸åŒæ–¹æ³•
    
    # æ‰¹é‡å¤„ç†
    analyzer.process_all_videos(csv_path, transcript_base_dir, output_base_dir, score_method)

if __name__ == "__main__":
    main()